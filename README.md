# PortfoRadar

[![CI](https://github.com/armanfeili/PortfoRadar/actions/workflows/ci.yml/badge.svg)](https://github.com/armanfeili/PortfoRadar/actions/workflows/ci.yml)

A NestJS application that ingests and serves KKR's investment portfolio company data through a queryable REST API.

## ðŸŒ Live Demo

| Resource | URL |
|----------|-----|
| **API** | https://portforadar-production.up.railway.app |
| **Swagger UI** | https://portforadar-production.up.railway.app/api/docs |
| **Health** | https://portforadar-production.up.railway.app/health |

> **Note**: If the deployed instance shows 0 companies, ingestion may need to be triggered. See [Ingesting Data on Deployed Instance](#ingesting-data-on-deployed-instance).

## Overview

PortfoRadar fetches portfolio company information from KKR's public API, normalizes the data, and stores it in MongoDB. It provides a comprehensive REST API with filtering, pagination, full-text search, and aggregated statistics.

## Features

- **Data Ingestion**: Automated fetching from KKR's portfolio API with field normalization
- **REST API**: Full CRUD-style endpoints with advanced filtering
- **Search**: Case-insensitive regex search across company names and descriptions
- **Pagination**: Offset-based pagination with configurable limits
- **Statistics**: Aggregated counts by asset class, industry, region, and year
- **OpenAPI Documentation**: Interactive Swagger UI at `/api`
- **Health Checks**: Kubernetes-ready health endpoints

## Tech Stack

| Component | Technology |
|-----------|------------|
| Runtime | Node.js 20 LTS |
| Language | TypeScript 5.7 |
| Framework | NestJS 11 |
| Database | MongoDB 7 + Mongoose |
| Logging | Pino (nestjs-pino) |
| Documentation | Swagger/OpenAPI |
| Testing | Jest |
| Container | Docker (multi-stage build) |

## Quick Start

### Option A: Docker Compose (Recommended)

The fastest way to get running:

```bash
# Clone and start
git clone <repository-url> && cd PortfoRadar
docker compose up --build

# In another terminal, ingest data
docker compose exec app npm run ingest:prod

# Verify data
curl http://localhost:3000/companies | jq '.total'
```

### Option B: Pre-built Docker Image

Pull the pre-built image from GitHub Container Registry:

```bash
# Pull latest image
docker pull ghcr.io/armanfeili/portfolioradar:latest

# Start MongoDB
docker run -d --name mongo -p 27017:27017 mongo:7

# Run the app
docker run -d --name portfolioradar \
  -p 3000:3000 \
  -e MONGO_URI=mongodb://host.docker.internal:27017/portfolioradar \
  ghcr.io/armanfeili/portfolioradar:latest

# Ingest data
docker exec portfolioradar node dist/ingest.js

# Verify
curl http://localhost:3000/companies | jq '.total'
```

> See [docs/CONTAINER_REGISTRY.md](docs/CONTAINER_REGISTRY.md) for more details.

### Option C: Local Development

**Prerequisites:**
- Node.js 20.x (`nvm use` if using nvm)
- MongoDB 7.x running locally or via Docker

```bash
# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Edit .env if needed (defaults work with local MongoDB)

# Start MongoDB (if not already running)
docker run -d -p 27017:27017 --name mongo mongo:7

# Start in development mode
npm run start:dev

# Ingest data
npm run ingest

# Open Swagger UI
open http://localhost:3000/api/docs
```

## Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3000` | HTTP server port |
| `MONGO_URI` | â€” | MongoDB connection string **(required)** |
| `NODE_ENV` | `development` | Environment mode |
| `LOG_LEVEL` | `info` | Log level (debug/info/warn/error) |
| `THROTTLE_TTL` | `60` | Rate limit window in seconds |
| `THROTTLE_LIMIT` | `100` | Max requests per window |
| `ALLOWED_ORIGINS` | â€” | Optional comma-separated list of allowed origins (e.g. `https://app.com,https://admin.app.com`). If unset or in non-production, CORS is fully open (`*`). |

## API Documentation

Interactive Swagger documentation available at `/api/docs` when running.

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/companies` | List companies with filters |
| GET | `/companies/:id` | Get single company by ID |
| GET | `/stats` | Aggregated statistics |
| GET | `/health` | Health check |
| POST | `/admin/keys` | Generate temporary admin key (public endpoint) |
| DELETE | `/admin/keys/:keyId` | Revoke a temporary key |
| POST | `/admin/ingest` | Trigger data ingestion (requires `X-Admin-Key` header) |

### Temporary Admin Keys

Generate short-lived API keys for admin operations.

**Generate a temporary key (no auth required):**
```bash
curl -X POST https://your-app.railway.app/admin/keys \
  -H "Content-Type: application/json" \
  -d '{"ttlMinutes": 30}'
```

Response (token shown **once only**):
```json
{
  "keyId": "507f1f77bcf86cd799439011",
  "token": "ak_a1b2c3d4e5f6...",
  "expiresAt": "2026-02-06T16:30:00.000Z",
  "ttlMinutes": 30
}
```

**Use the temp key for admin operations:**
```bash
curl -X POST https://your-app.railway.app/admin/ingest \
  -H "X-Admin-Key: ak_a1b2c3d4e5f6..."
```

**Via Swagger UI:**
1. Open `/api/docs`
2. Find **Admin â†’ POST /admin/keys**
3. Execute (no header required)
4. Copy the returned token
5. Use that token in `X-Admin-Key` header for `/admin/ingest`

> **Security Notes:**
> - Token is shown **once only** â€” store it securely
> - TTL: 5-1440 minutes (default: 30)
> - MongoDB TTL index auto-deletes expired keys
> - Revoke manually via `DELETE /admin/keys/:keyId`

### Ingesting Data on Deployed Instance

The `/admin/ingest` endpoint allows triggering data ingestion without CLI access â€” perfect for deployed instances.

**Via curl:**
```bash
curl -X POST https://your-app.railway.app/admin/ingest \
  -H "X-Admin-Key: your-admin-key-or-ak_xxx"
```

**Verify:**
```bash
curl https://your-app.railway.app/companies | jq '.total'
# Should return > 0 after successful ingestion
```

> **Security:** Admin endpoints require a valid temporary key (generated via `POST /admin/keys`). Keys expire automatically based on TTL.

### Query Parameters for `/companies`

| Parameter | Type | Description |
|-----------|------|-------------|
| `page` | number | Page number (default: 1) |
| `limit` | number | Items per page (default: 20, max: 100) |
| `assetClass` | string | Filter by asset class |
| `industry` | string | Filter by industry |
| `region` | string | Filter by region |
| `yoi` | string | Filter by year of investment |
| `q` | string | Full-text search (name, description) |
| `sort` | string | Sort field (e.g., `name`, `-yearOfInvestment`) |

### Example Requests

```bash
# List all companies
curl http://localhost:3000/companies

# Filter by asset class
curl "http://localhost:3000/companies?assetClass=Private%20Equity"

# Search with pagination
curl "http://localhost:3000/companies?q=technology&page=2&limit=10"

# Get statistics
curl http://localhost:3000/stats

# Get single company
curl http://localhost:3000/companies/abc123def456...
```

### Response Shape

```json
{
  "items": [
    {
      "companyId": "a1b2c3d4...",
      "name": "Acme Corp",
      "nameSort": "acme corp",
      "assetClassRaw": "Private Equity, Tech Growth",
      "assetClasses": ["Private Equity", "Tech Growth"],
      "industry": "Technology",
      "region": "Americas",
      "headquarters": "San Francisco, CA",
      "yearOfInvestment": "2023",
      "website": "https://acme.com",
      "logoUrl": "https://www.kkr.com/content/dam/...",
      "descriptionText": "A leading technology company..."
    }
  ],
  "page": 1,
  "limit": 20,
  "total": 150,
  "totalPages": 8,
  "_links": {
    "self": "/companies?page=1",
    "first": null,
    "prev": null,
    "next": "/companies?page=2",
    "last": "/companies?page=8"
  }
}
```

### Error Response Format

All errors follow a consistent format:

```json
{
  "statusCode": 404,
  "error": "Not Found",
  "message": "Company with id 'abc123' not found",
  "path": "/companies/abc123",
  "timestamp": "2026-02-06T10:30:00.000Z"
}
```

## Project Structure

```
src/
â”œâ”€â”€ app.module.ts                   # Root module
â”œâ”€â”€ main.ts                         # Application bootstrap
â”œâ”€â”€ ingest.ts                       # CLI ingestion entrypoint
â”œâ”€â”€ config/
â”‚   â””â”€â”€ env.validation.ts           # Zod environment validation
â”œâ”€â”€ companies/
â”‚   â”œâ”€â”€ companies.module.ts         # Companies feature module
â”‚   â”œâ”€â”€ companies.controller.ts     # REST endpoints (companies + stats)
â”‚   â”œâ”€â”€ companies.service.ts        # Business logic
â”‚   â”œâ”€â”€ companies.repository.ts     # MongoDB operations
â”‚   â”œâ”€â”€ dto/                        # Data transfer objects
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ company.schema.ts       # Mongoose schema
â”œâ”€â”€ database/
â”‚   â””â”€â”€ database.module.ts          # MongoDB connection module
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ ingestion.module.ts         # Ingestion feature module
â”‚   â”œâ”€â”€ portfolio-ingest.service.ts # Ingestion orchestration
â”‚   â”œâ”€â”€ ingestion-run.repository.ts # Run tracking repository
â”‚   â”œâ”€â”€ kkr-client/                 # KKR API client
â”‚   â”‚   â”œâ”€â”€ kkr.client.ts           # HTTP client with retry
â”‚   â”‚   â””â”€â”€ kkr-api.types.ts        # API type definitions
â”‚   â”œâ”€â”€ mappers/
â”‚   â”‚   â””â”€â”€ company.mapper.ts       # Raw â†’ DTO transformation
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ ingestion-run.schema.ts # Run tracking schema
â”œâ”€â”€ health/
â”‚   â”œâ”€â”€ health.module.ts            # Health module
â”‚   â””â”€â”€ health.controller.ts        # Health check endpoint
â””â”€â”€ scripts/
    â”œâ”€â”€ test-upsert.ts              # Upsert verification script
    â””â”€â”€ verify-data.ts              # Data quality verification

docs/
â”œâ”€â”€ DEVELOPMENT_PHASES.md           # Implementation roadmap
â”œâ”€â”€ source-analysis.md              # KKR API analysis
â””â”€â”€ Code_Challenge.txt              # Challenge requirements

test/
â”œâ”€â”€ app.e2e-spec.ts                 # E2E tests
â””â”€â”€ jest-e2e.json                   # Jest E2E config
```

## Available Scripts

| Script | Description |
|--------|-------------|
| `npm run start:dev` | Start in watch mode (development) |
| `npm run start:prod` | Start compiled production build |
| `npm run build` | Compile TypeScript to JavaScript |
| `npm run lint` | Run ESLint |
| `npm run test` | Run unit tests |
| `npm run test:e2e` | Run end-to-end tests |
| `npm run ingest` | Ingest portfolio data from KKR API |
| `npm run ingest:prod` | Ingest using compiled JS (for Docker) |
| `npm run verify:data` | Verify ingested data integrity |

## CLI Usage Guide

### Data Ingestion

The ingestion CLI fetches all portfolio companies from KKR's public API and stores them in MongoDB.

```bash
# Development mode (uses ts-node)
npm run ingest

# Production mode (uses compiled JS, for Docker)
npm run ingest:prod
```

**Expected output:**
```
========================================
        INGESTION SUMMARY
========================================
Run ID:          550e8400-e29b-41d4-a716-446655440000
Status:          COMPLETED
Duration:        10854ms
----------------------------------------
Fetched:         296
Unique:          296
Created:         296
Updated:         0
Failed:          0
----------------------------------------
Source total:    296
Source pages:    20
Accum. attempts: 1
Complete:        âœ… YES
========================================
```

### Data Verification

Verify the integrity of ingested data:

```bash
npm run verify:data
```

**Expected output:**
```
=== Data Verification Report ===
âœ“ Total companies: 296
âœ“ Source total (from API): 296
âœ“ Missing required fields: 0
âœ“ Duplicate companyIds: 0

--- Distribution Sanity Check ---
By Asset Class:
  Private Equity: 148
  Infrastructure: 67
  Tech Growth: 55
  ...

By Region:
  Americas: 123
  Asia Pacific: 93
  Europe, The Middle East And Africa: 79
  Japan: 1

âœ“ Data quality: PASS
```

## MongoDB Console Commands

For reviewers who prefer database-level inspection, here are useful `mongosh` one-liners:

```bash
# Connect to MongoDB (local)
mongosh portfolioradar

# Connect via Docker Compose
docker compose exec mongo mongosh portfolioradar
```

### Quick Inspection Commands

```javascript
// Count total companies
db.companies.countDocuments()
// Expected: 296

// Verify unique company IDs
db.companies.distinct("companyId").length
// Expected: 296

// Check for missing required fields
db.companies.countDocuments({
  $or: [
    { name: { $exists: false } },
    { assetClasses: { $size: 0 } },
    { industry: "" },
    { region: "" }
  ]
})
// Expected: 0

// Distribution by region
db.companies.aggregate([
  { $group: { _id: "$region", count: { $sum: 1 } } },
  { $sort: { count: -1 } }
])

// Distribution by asset class (array field)
db.companies.aggregate([
  { $unwind: "$assetClasses" },
  { $group: { _id: "$assetClasses", count: { $sum: 1 } } },
  { $sort: { count: -1 } }
])

// Find companies by name (regex search)
db.companies.find({ name: /acme/i }, { name: 1, region: 1, industry: 1 })

// Get last ingestion run
db.ingestionruns.findOne({}, { sort: { startedAt: -1 } })

// View sample company document
db.companies.findOne()

// Check document uniqueness
db.companies.aggregate([
  { $group: { _id: "$companyId", count: { $sum: 1 } } },
  { $match: { count: { $gt: 1 } } }
])
// Expected: empty (no duplicates)
```

### Docker Compose One-Liners

```bash
# Full uniqueness verification
docker compose exec mongo mongosh portfolioradar --quiet --eval \
  'printjson({
    docs: db.companies.countDocuments(),
    uniqueIds: db.companies.distinct("companyId").length,
    uniqueNames: db.companies.distinct("name").length
  })'
# Expected: { docs: 296, uniqueIds: 296, uniqueNames: 296 }

# Check ingestion status
docker compose exec mongo mongosh portfolioradar --quiet --eval \
  'db.ingestionruns.findOne({}, { sort: { startedAt: -1 } })'
```

## Docker

### Build Image

```bash
docker build -t portfolioradar .
```

### Run with Docker Compose

```bash
# Start app + MongoDB
docker compose up -d

# View logs
docker compose logs -f app

# Stop
docker compose down
```

The Docker setup includes:
- Multi-stage build for minimal image size
- Non-root user for security
- Health checks for orchestration
- Volume persistence for MongoDB

## How KKR Portfolio Data Is Retrieved

We fetch KKR portfolio companies from the public portfolio listing endpoint used by [kkr.com/invest/portfolio](https://www.kkr.com/invest/portfolio).

The endpoint behaves like a paginated JSON API:

| Field | Description |
|-------|-------------|
| `hits` | Total company count (currently 296) |
| `pages` | Total pages (currently 20, fixed 15 items/page) |
| `results` | Array of company records |

**CDN behavior:** The endpoint is served via CDN. In practice, page responses may vary across edge nodes, occasionally returning incomplete sets when pages are fetched concurrently. Our ingestion handles this with an accumulation loop (see below).

## Data Model & Idempotent Storage

Each company is stored in MongoDB with a stable unique `companyId`:

```
companyId = SHA256(name + hq).substring(0, 32)
```

**Upsert behavior:**
- Insert if document missing
- Update only when `contentHash` differs (hash of all business fields)
- Skip write entirely if content unchanged

**Guarantees:**
- **No duplicates** â€” unique index on `companyId`
- **Safe repeated runs** â€” idempotent upserts
- **Minimal write load** â€” update-only-if-changed via content hash

## Reliability Guarantees (Completeness Reporting)

We verify completeness by comparing accumulated unique companies against the source-reported total. The CLI output includes:

```
========================================
        INGESTION SUMMARY
========================================
Run ID:          <uuid>
Status:          COMPLETED
Duration:        10854ms
----------------------------------------
Fetched:         296
Unique:          296
Created:         0
Updated:         0
Failed:          0
----------------------------------------
Source total:    296
Source pages:    20
Accum. attempts: 1
Complete:        âœ… YES
========================================
```

**Accumulation loop:** If the first fetch pass returns fewer than `sourceTotal` companies (due to CDN variability), we retry up to 5 times, accumulating unique companies until complete.

## Design Decisions

### 1. Deterministic Company IDs
Companies are assigned SHA256 hashes (32-char hex) derived from `name + hq` (normalized to lowercase), ensuring idempotent upserts during re-ingestion.

### 2. Field Normalization
- `assetClassRaw` preserved for display; `assetClasses[]` split for filtering
- `descriptionText` stripped of HTML for search; `descriptionHtml` preserved
- `logoUrl` made absolute; `website` normalized with protocol

### 3. Pagination Strategy
Offset-based pagination with `page`/`limit` parameters. Response includes `totalPages` for UI pagination components.

### 4. Search Implementation
Case-insensitive regex search on `name` and `descriptionText` fields with proper input escaping to prevent regex injection.

### 5. Logging
Structured JSON logging via Pino for production observability. Request correlation IDs included automatically.

## Testing

```bash
# Unit tests
npm run test

# Unit tests with coverage
npm run test:cov

# E2E tests (requires MongoDB)
npm run test:e2e
```

## CI/CD

GitHub Actions workflow runs on push/PR to main:
1. Install dependencies
2. Run linter
3. Run unit tests
4. Build TypeScript
5. Build Docker image

See [.github/workflows/ci.yml](.github/workflows/ci.yml).

## License

MIT License â€” see [LICENSE](LICENSE) for details.
