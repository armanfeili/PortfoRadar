# PortfoRadar â€” Development Phases

> **Approach**: Complete each phase fully before moving to the next.  
> **Principle**: "Better to do less but well, than everything poorly."

---

## Technology Stack

### Core Stack

| Category | Technology | Notes |
|----------|------------|-------|
| **Runtime** | Node.js 20 LTS | |
| **Language** | TypeScript | Strict mode recommended |
| **Framework** | NestJS | Modules, services, dependency injection |
| **Database** | MongoDB + Mongoose | @nestjs/mongoose integration |

### Packages by Phase

#### Phase 2: Config + Database + Logging
```bash
npm install @nestjs/config zod                    # Configuration + validation
npm install @nestjs/mongoose mongoose             # Database ODM
npm install nestjs-pino pino-http pino-pretty     # Structured logging
```

#### Phase 4: Ingestion
```bash
npm install undici p-retry p-limit                # HTTP client + retry + concurrency
```

#### Phase 5: REST API
```bash
npm install @nestjs/swagger swagger-ui-express    # API documentation
npm install class-validator class-transformer     # DTO validation
```

#### Phase 7: Production Polish
```bash
npm install -D jest @nestjs/testing ts-jest       # Testing
```

#### Phase 8: Bonus (Optional)
```bash
npm install helmet @nestjs/throttler              # Security hardening
```

### Database Indexes

| Collection | Index | Type |
|------------|-------|------|
| `companies` | `companyId` | Unique |
| `companies` | `assetClasses` | Multikey (array) |
| `companies` | `industry` | Query |
| `companies` | `region` | Query |
| `companies` | `name` | Text (optional) |
| `companies` | `nameSort` | Sort (optional) |

### Quality & DevX

| Category | Tools |
|----------|-------|
| **Lint / Format** | ESLint, Prettier (included with NestJS) |
| **Testing** | Jest (NestJS default) |
| **Containerization** | Docker, Docker Compose |
| **CI** | GitHub Actions |

### Configuration (Environment Variables)

```bash
# .env.example
PORT=3000
MONGO_URI=mongodb://localhost:27017/portfolioradar

# Optional (Phase 8 bonus)
ENABLE_NL_QUERY=false
OPENAI_API_KEY=
```

---

## Definition of Done (Final Acceptance Checklist)

Before submitting, verify ALL of these with the provided commands:

| Requirement | Verify Command | Expected Result |
|-------------|----------------|------------------|
| Ingests ALL companies | `npm run ingest` | `fetched == sourceTotal` (where `sourceTotal` comes from API response) |
| Required fields stored | `npm run verify:data` | 0 companies missing name/assetClasses/industry/region |
| Well-structured schema | Check `src/companies/schemas/` | Indexes defined, types explicit |
| Idempotent ingestion | Run `npm run ingest` twice | Second run shows updates, not new inserts |
| REST API works | `curl localhost:3000/companies` | Returns `{ items: [...], page, limit, total, totalPages }` |
| Swagger UI | Open `http://localhost:3000/api/docs` | Interactive docs load |
| Docker works | `docker compose up --build` | App + Mongo start, API responds |
| README complete | Read `README.md` | Setup â†’ Ingest â†’ Query flow is clear |
| Clean git history | `git log --oneline` | Meaningful commit messages |

> **Note on "ALL companies"**: The KKR API uses `hits` as the total company count (currently 296). Store `hits` in `IngestionRun.sourceMeta.totalFromSource` and `pages` in `sourceMeta.pagesFromSource`. Verify `fetched == totalFromSource`.

---

## âœ… PHASE 0 â€” Source Reconnaissance (COMPLETE)

**Goal**: Understand exactly how KKR serves portfolio data before writing any code.

**Status**: âœ… **COMPLETE** â€” See `docs/source-analysis.md` for full details.

### Key Findings Summary

| Item | Discovery |
|------|----------|
| **API Endpoint** | `GET https://www.kkr.com/content/kkr/sites/global/en/invest/portfolio/jcr:content/root/main-par/bioportfoliosearch.bioportfoliosearch.json` |
| **Method** | GET |
| **Auth Required** | None |
| **Pagination** | Page-based (`?page=1`), 15 items/page (fixed), read `pages` from response |
| **Total Companies** | 296 (as of 2026-02-03, read from `hits` field) |
| **Unique ID** | âš ï¸ None provided â€” use deterministic hash (`kkrKey`) |

### API Response Fields

```typescript
interface KkrApiResponse {
  success: boolean;
  hits: number;      // Total companies (e.g., 296)
  pages: number;     // Total pages (e.g., 20)
  results: PortfolioCompany[];
}

interface PortfolioCompany {
  name: string;           // Company name
  assetClass: string;     // May contain multiple (comma-separated)
  industry: string;
  region: string;         // Single string, NOT an array!
  hq: string;             // Headquarters
  yoi: string;            // Year of Investment
  url: string;            // Website (may be empty)
  description: string;    // âš ï¸ Contains HTML markup!
  logo: string;           // Relative path
  // Optional:
  relatedLinkOne?: string;
  relatedLinkOneTitle?: string;
}
```

### âš ï¸ Critical Notes from Recon

1. **`limit` parameter is IGNORED** â€” API always returns 15 items per page
2. **`region` is a single string**, not an array (e.g., `"Americas"`, `"Asia Pacific"`)
3. **No unique ID provided** â€” must generate `companyId` via hash
4. **`description` contains HTML** â€” sanitize before display
5. **Do NOT store `sortingName`** â€” it changes based on sort parameter

### Deliverable
- [x] Created `docs/source-analysis.md` with full findings

---

## âœ… PHASE 1 â€” Repository & Engineering Baseline (COMPLETE)

**Goal**: Professional repo structure that's easy to run and review.

**Status**: âœ… **COMPLETE** â€” NestJS scaffolded, linting works, dev server runs.

### What Was Done

1. **Moved existing files temporarily** before scaffolding (docs/, HAR files, etc.)
2. **Switched to Node.js 20 LTS** (`nvm use 20`)
3. **Scaffolded NestJS** with `npx @nestjs/cli new . --package-manager npm --skip-git`
4. **Restored original files** and reorganized:
   - `docs/` â€” Development phases, source analysis, challenge requirements
   - `docs/research/` â€” HAR captures (git-ignored, ~10MB)
5. **Created essential config files**:
   - `.gitignore` â€” Comprehensive exclusions including `*.har`, `docs/research/`
   - `.editorconfig` â€” Consistent formatting (2-space indent, LF, UTF-8)
   - `.env.example` â€” Template with `PORT` and `MONGO_URI`
   - `.nvmrc` â€” Pins Node.js 20
6. **Updated `package.json`**:
   - Added `"dev"` script alias for `nest start --watch`
   - Set proper `name`, `description`, `author`, `license` (MIT)
7. **Fixed ESLint warning** in `src/main.ts` (floating promise â†’ `void bootstrap()`)
8. **Replaced README.md** with project-specific documentation

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `.gitignore` | Created | Excludes `node_modules/`, `dist/`, `.env`, `*.har`, `docs/research/` |
| `.editorconfig` | Created | 2-space indent, LF line endings, UTF-8 |
| `.env.example` | Created | `PORT=3000`, `MONGO_URI=mongodb://localhost:27017/portfolioradar` |
| `.nvmrc` | Created | Pins Node.js version to `20` |
| `README.md` | Replaced | Project overview, quick start, available scripts |
| `package.json` | Modified | Added `dev` script, description, author, MIT license |
| `src/main.ts` | Modified | Fixed floating promise lint warning |
| `docs/research/` | Created | Moved HAR files here (git-ignored) |

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Format works | `npm run format` | âœ… Success |
| Dev server starts | `npm run start:dev` | âœ… "Nest application successfully started" |
| Endpoint responds | `curl localhost:3000` | âœ… Returns "Hello World!" |

### Deliverables
- [x] `npm run lint` works without errors
- [x] `npm run start:dev` starts the default Nest app
- [x] Project structure matches NestJS conventions
- [x] Root directory is clean (research files in `docs/research/`)

---

## âœ… PHASE 2 â€” Config Validation + Database + Logging (COMPLETE)

**Goal**: Running NestJS app connected to MongoDB with validated config and structured logging.

**Status**: âœ… **COMPLETE** â€” Config validation, MongoDB connection, Pino logging, and health endpoint all working.

### What Was Done

1. **Installed Phase 2 dependencies**:
   - `@nestjs/config` + `zod` for env validation
   - `@nestjs/mongoose` + `mongoose` for MongoDB
   - `nestjs-pino` + `pino-http` + `pino-pretty` for structured logging

2. **Created configuration validation** (`src/config/env.validation.ts`):
   - Zod schema validates `PORT` (number, defaults to 3000) and `MONGO_URI` (required URL)
   - App fails fast with clear error message if validation fails

3. **Created database module** (`src/database/database.module.ts`):
   - Connects to MongoDB using `MONGO_URI` from validated config
   - Uses `MongooseModule.forRootAsync()` for async config injection

4. **Created health module** (`src/health/`):
   - `HealthController` exposes `GET /health` â†’ `{ status: "ok" }`
   - `HealthModule` registers the controller

5. **Updated app.module.ts**:
   - Integrated `ConfigModule.forRoot()` with Zod validation
   - Added `LoggerModule.forRoot()` with pino-pretty for dev, JSON for prod
   - Imported `DatabaseModule` and `HealthModule`

6. **Updated main.ts**:
   - Uses `bufferLogs: true` for proper log ordering
   - Applies pino logger to all NestJS logs
   - Reads PORT from validated ConfigService

7. **Created local .env** from .env.example (git-ignored)

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `src/config/env.validation.ts` | Created | Zod schema + validateEnv function |
| `src/database/database.module.ts` | Created | Mongoose connection module |
| `src/health/health.controller.ts` | Created | Health check endpoint |
| `src/health/health.module.ts` | Created | Health module |
| `src/app.module.ts` | Modified | Integrated Config, Logger, Database, Health modules |
| `src/main.ts` | Modified | Added pino logger + ConfigService for PORT |
| `.env` | Created | Local environment variables (git-ignored) |

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Dev server starts | `npm run dev` | âœ… Starts with structured pino logs |
| Health endpoint | `curl localhost:3000/health` | âœ… Returns `{"status":"ok"}` |
| HTTP request logging | (any request) | âœ… Pino logs request/response with timing |
| Missing MONGO_URI fails | `MONGO_URI= node dist/main.js` | âœ… Crashes with clear ZodError |

### Deliverables
- [x] `npm run dev` starts server successfully
- [x] `GET http://localhost:3000/health` returns OK
- [x] App crashes with clear error if `MONGO_URI` is missing

---

## âœ… PHASE 3 â€” Data Model (Schemas + Repositories) (COMPLETE)

**Goal**: Well-structured MongoDB schema with idempotent upsert capability.

**Status**: âœ… **COMPLETE** â€” Company and IngestionRun schemas created, repository with idempotent upsert verified.

### What Was Done

1. **Created Company Schema** (`src/companies/schemas/company.schema.ts`):
   - Required fields: `companyId` (unique), `name`, `nameSort`, `assetClassRaw`, `assetClasses[]`, `industry`, `region`
   - Optional fields: `descriptionHtml`, `descriptionText`, `website`, `headquarters`, `yearOfInvestment`, `logoPath`, `logoUrl`, `relatedLinks`
   - Source metadata: `source.listUrl`, `source.endpoint`, `source.fetchedAt`
   - Indexes: `companyId` (unique), `nameSort`, `assetClasses` (multikey), `industry`, `region`, compound `industry+region`

2. **Created IngestionRun Schema** (`src/ingestion/schemas/ingestion-run.schema.ts`):
   - Fields: `runId`, `startedAt`, `finishedAt`, `status`, `counts`, `errorMessages` (renamed from `errors` to avoid Mongoose reserved path)
   - Source metadata: `listUrl`, `endpointUsed`, `totalFromSource`, `pagesFromSource`, `asOf`, `scopeNote`
   - Indexes: `startedAt` (descending), compound `status+startedAt`

3. **Created Companies Repository** (`src/companies/companies.repository.ts`):
   - `upsertCompany(dto)` â€” idempotent insert/update by `companyId`
   - `bulkUpsert(dtos)` â€” batch upsert with bulkWrite
   - `findAll(filters, pagination)` â€” paginated query with filters for assetClass, industry, region, search
   - `findByCompanyId(id)` â€” single document lookup
   - `countByField(field)` â€” aggregation for stats
   - `countAll()` â€” total document count
   - `deleteAll()` â€” for testing

4. **Created Modules**:
   - `CompaniesModule` â€” registers Company schema, exports CompaniesRepository
   - `IngestionModule` â€” registers IngestionRun schema

5. **Updated AppModule** with new module imports

6. **Created Test Script** (`src/scripts/test-upsert.ts`):
   - Verifies upsert idempotency (run twice = no duplicates)
   - Verifies updates apply correctly

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `src/companies/schemas/company.schema.ts` | Created | Company Mongoose schema with indexes |
| `src/companies/companies.repository.ts` | Created | Data access layer with upsert |
| `src/companies/companies.module.ts` | Created | Companies NestJS module |
| `src/ingestion/schemas/ingestion-run.schema.ts` | Created | IngestionRun schema for tracking |
| `src/ingestion/ingestion.module.ts` | Created | Ingestion NestJS module |
| `src/app.module.ts` | Modified | Added CompaniesModule, IngestionModule imports |
| `src/scripts/test-upsert.ts` | Created | Upsert idempotency verification script |

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Build passes | `npm run build` | âœ… No errors |
| Server starts | `npm run start:dev` | âœ… All modules load correctly |
| Health endpoint | `curl localhost:3000/health` | âœ… `{"status":"ok"}` |
| Upsert test | `npx ts-node src/scripts/test-upsert.ts` | âœ… PASS: no duplicates |

### Upsert Idempotency Test Results

```
1. First upsert:  created=true,  updated=false â†’ count=1
2. Second upsert: created=false, updated=true  â†’ count=1 (no duplicate)
3. Third upsert:  created=false, updated=true  â†’ count=1 (field updated)
âœ… PASS: Upsert is idempotent - no duplicates created
```

### Deliverables
- [x] Schemas defined with proper TypeScript types
- [x] Indexes visible in schema code
- [x] Upsert tested: same company doesn't duplicate

---

## âœ… PHASE 4 â€” Ingestion Service (Core Feature) (COMPLETE)

**Goal**: Retrieve ALL companies from KKR and store in MongoDB.

**Status**: âœ… **COMPLETE** â€” KKR HTTP client, company mapper, ingestion service, and verification script all working.

### What Was Done

1. **Installed Phase 4 dependencies**: `undici`, `p-retry`, `p-limit`
2. **Created KKR HTTP Client** (`src/ingestion/kkr-client/kkr.client.ts`):
   - Page-based pagination (1-indexed, 15 items/page fixed by API)
   - 30s timeout, 3 retries with exponential backoff (1s â†’ 2s â†’ 4s)
   - Concurrency limit of 3 concurrent requests
   - Proper User-Agent and Accept headers
3. **Created Company Mapper** (`src/ingestion/mappers/company.mapper.ts`):
   - Deterministic `companyId` via SHA256 hash of `name + hq`
   - Generates `contentHash` from business fields for update-only-if-changed optimization
   - Splits `assetClassRaw` into `assetClasses[]` array
   - Strips HTML from description, normalizes URLs, builds full logo URLs
4. **Created Ingestion Run Repository** (`src/ingestion/ingestion-run.repository.ts`):
   - CRUD operations for IngestionRun documents
   - Tracks `sourceMeta.totalFromSource` and `sourceMeta.pagesFromSource`
5. **Created Portfolio Ingest Service** (`src/ingestion/portfolio-ingest.service.ts`):
   - Fetches all pages, deduplicates in memory by companyId
   - Bulk upserts to MongoDB, tracks created/updated/failed counts
6. **Created Entry Scripts**:
   - `src/ingest.ts` â€” Bootstrap script for `npm run ingest`
   - `src/scripts/verify-data.ts` â€” Data quality verification
7. **Updated IngestionModule** with new providers

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `src/ingestion/kkr-client/kkr-api.types.ts` | Created | TypeScript interfaces for KKR API |
| `src/ingestion/kkr-client/kkr.client.ts` | Created | HTTP client with retry/concurrency |
| `src/ingestion/mappers/company.mapper.ts` | Created | Raw API â†’ UpsertCompanyDto mapper |
| `src/ingestion/ingestion-run.repository.ts` | Created | IngestionRun CRUD operations |
| `src/ingestion/portfolio-ingest.service.ts` | Created | Main ingestion orchestration |
| `src/ingestion/ingestion.module.ts` | Modified | Added providers |
| `src/ingest.ts` | Created | Entry script for `npm run ingest` |
| `src/scripts/verify-data.ts` | Created | Data quality verification |
| `package.json` | Modified | Added `ingest` and `verify:data` scripts |

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Build passes | `npm run build` | âœ… No errors |
| Ingestion works | `npm run ingest` | âœ… Fetched: 296, Source total: 296 |
| Data quality | `npm run verify:data` | âœ… PASS (0 missing fields, 0 duplicates) |
| Idempotent | Run `npm run ingest` twice | âœ… Second run shows updates, not new inserts |

### 4.1 KKR HTTP Client

Create `src/ingestion/kkr-client/kkr.client.ts`:

**Pick ONE stack and stick with it** (to avoid churn):

| Option | Install | Pros |
|--------|---------|------|
| **A: undici (recommended)** | `npm install undici p-retry p-limit` | Lean, explicit, fewer abstractions |
| B: Axios + Nest | `npm install @nestjs/axios axios axios-retry` | More Nest-ish, familiar |

```bash
# Recommended: lean stack
npm install undici p-retry p-limit
```

- [x] Implement `fetchPortfolioPage(pageNumber: number)` â€” **page-based, NOT offset/limit**
  ```typescript
  // API uses page-based pagination (1-indexed)
  // The `limit` parameter is IGNORED â€” always returns 15 items
  const url = `${BASE_ENDPOINT}?page=${pageNumber}&sortParameter=name&sortingOrder=asc`;
  ```
- [x] **Set proper headers**:
  ```typescript
  headers: {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    'Accept': 'application/json',
  }
  ```
- [x] Add timeout (e.g., 30 seconds)
- [x] Add retry with exponential backoff (3 retries, 1s â†’ 2s â†’ 4s)
- [x] **Concurrency cap**: Max 3-5 concurrent requests (don't hammer the site)
- [x] Handle rate limiting gracefully (429 â†’ back off)

### 4.2 Response Mapper

Create `src/ingestion/mappers/company.mapper.ts`:

- [x] `mapRawToCompany(rawItem): CompanyDto`
- [x] Handle missing fields gracefully
- [x] Generate `companyId` using deterministic hash
- [x] Compute derived fields:
  ```typescript
  // Split asset classes
  assetClassRaw: raw.assetClass,
  assetClasses: raw.assetClass.split(',').map(s => s.trim()),
  
  // Normalize/compute
  nameSort: raw.name.toLowerCase(),
  descriptionHtml: raw.description,
  descriptionText: stripHtml(raw.description),
  website: normalizeUrl(raw.url),  // add https:// if missing
  logoUrl: raw.logo ? `https://www.kkr.com${raw.logo}` : undefined,
  ```

### 4.3 Portfolio Ingestion Service

Create `src/ingestion/portfolio-ingest.service.ts`:

```typescript
async ingestAll(): Promise<IngestionResult> {
  // 1. Create ingestion run record
  // 2. Fetch all pages (handle pagination)
  // 3. De-duplicate in memory by companyId (same company may appear in multiple filters)
  // 4. For each unique company: map â†’ upsert
  // 5. Track counts (created, updated, failed)
  // 6. Update run record with results
  // 7. Return summary
}
```

#### De-duplication Strategy

Same company may appear across pages/filters. Handle with **two layers**:
1. **In-memory Set** of `companyId` â€” skip if already processed this run
2. **DB upsert + unique index** â€” guarantees no duplicates even if Set fails

- [x] **Critical**: Do NOT let one company failure crash entire run
- [x] Log progress: "Fetched page 1/20", "Upserted company X"
- [x] Log summary at end: "Ingestion complete: 296 fetched, 290 created, 6 updated, 0 failed"

### 4.4 Ingestion Command

Option A: NestJS CLI command
```bash
npm install nestjs-command
```

Option B: Separate bootstrap script
```typescript
// src/ingest.ts
async function bootstrap() {
  const app = await NestFactory.createApplicationContext(AppModule);
  const service = app.get(PortfolioIngestService);
  await service.ingestAll();
  await app.close();
}
```

- [x] Add npm script: `"ingest": "ts-node src/ingest.ts"`

### 4.5 Test Ingestion

```bash
# Start MongoDB (docker or local)
docker run -d -p 27017:27017 --name mongo mongo:7

# Run ingestion
npm run ingest
```

- [x] Verify all companies are in database
- [x] Run again â†’ verify no duplicates (idempotent)

### 4.6 Add Data Verification Script (First-Class Citizen)

Create `src/scripts/verify-data.ts`:

```typescript
// REQUIRED checks:
// 1. Total companies count
// 2. Missing required fields (name, assetClass, industry, regions)
// 3. Duplicate companyIds (should be 0 â€” unique index guarantees this)
// 4. Last ingestion run: fetched == sourceMeta.totalFromSource

// OPTIONAL sanity checks:
// 5. Counts by assetClass (distribution)
// 6. Counts by industry (distribution)
// 7. Counts by region (distribution)
// 8. Companies with empty regions array (flag for review)
```

Add npm script:
```json
"verify:data": "ts-node src/scripts/verify-data.ts"
```

Expected output:
```
=== Data Verification Report ===
âœ“ Total companies: 296
âœ“ Source total (from API): 296
âœ“ Missing required fields: 0
âœ“ Duplicate companyIds: 0

--- Distribution Sanity Check ---
By Asset Class:
  Private Equity: 148
  Infrastructure: 67
  Tech Growth: 55
  Health Care Growth: 30
  Global Impact: 18
  (Note: totals > 296 because some companies have multiple asset classes)

By Region:
  Americas: 123
  Asia Pacific: 93
  Europe, The Middle East And Africa: 79
  Japan: 1

âœ“ Data quality: PASS
```

### 4.7 Commit

```bash
git add .
git commit -m "feat: implement KKR portfolio ingestion with idempotent upsert"
```

### Deliverables
- [x] `npm run ingest` populates database
- [x] `npm run verify:data` shows all required fields present
- [x] Re-running doesn't create duplicates (check with `npm run ingest` twice)

### Data Uniqueness, Idempotency, and CDN Variability Mitigation

#### Unique Identity Strategy (Stable Key)

Each company is stored with a stable unique `companyId` derived deterministically from:

```
companyId = SHA256(lowercase(name) + "|" + lowercase(hq)).substring(0, 32)
```

**Why `name + hq`?**
- The KKR API provides no unique identifiers
- Company names are unique per headquarters (e.g., "ON*NET Fibra" exists in both Chile and Colombia with different HQs)
- Both fields are always present and stable across API responses

**Uniqueness enforcement:**
- Database: unique index on `companyId`
- Ingestion: in-memory `Map<companyId, Company>` deduplicates before upsert

#### Update Semantics (Upsert + Update-Only-If-Changed)

Ingestion uses upsert semantics with content-hash optimization:

```
1. Map raw KKR record â†’ Company DTO
2. Compute contentHash = SHA256(JSON.stringify(businessFields)).substring(0, 32)
   - Includes: name, assetClass, industry, region, description, url, hq, yoi, logo, relatedLinks
   - Excludes: source.fetchedAt, createdAt, updatedAt (volatile fields)
3. Upsert by companyId:
   - If document missing: INSERT
   - If existing.contentHash === new.contentHash: SKIP (no write)
   - If hashes differ: UPDATE
```

This avoids rewriting unchanged documents and makes reruns cheap and truly idempotent.

#### Achievements / Acceptance Evidence

| Metric | Observed Value |
|--------|----------------|
| Source total | 296 companies across 20 pages |
| Completeness | "Complete: âœ… YES" in every run |
| Fresh DB ingestion | Created: 296, Updated: 0 |
| Rerun (no upstream changes) | Created: 0, Updated: 0 |
| Duration (fresh) | ~25s |
| Duration (rerun, no changes) | ~10-18s |

**Before optimization:** Each rerun wrote `Updated: 296` even when nothing changed.  
**After optimization:** Rerun shows `Updated: 0` â€” true idempotency.

#### CDN Variability and Our Fix (Accumulation Loop + Sequential Fetch)

The KKR portfolio endpoint is served behind a CDN. Different edge nodes can return **inconsistent or incomplete paginated results** within a single run:

- Some pages may omit companies that appear on other edges
- Concurrent requests may hit different edge nodes
- A single fetch pass may collect only 281-295 of 296 companies

**Root cause:** Upstream CDN caching/edge switching â€” not a bug in our code.

**Mitigation implemented:**

| Strategy | Implementation |
|----------|----------------|
| Sequential fetching | Fetch pages one-by-one with 100ms delay to reduce edge switching |
| Keep-alive agent | Reuse HTTP connections via `undici` Agent |
| Accumulation loop | Retry full fetch up to 5 times, accumulating unique companies by name until `count === sourceTotal` |
| Completeness reporting | Log warning if incomplete; show `Complete: âœ… YES / âš ï¸ NO` in summary |

**Result:** Reliably collects all 296 companies in 1-2 accumulation attempts.

#### Verification Commands

```bash
# Reset and run fresh
docker compose down -v && docker compose up -d --build
docker compose exec app npm run ingest:prod

# Verify completeness
curl -s http://localhost:3000/companies | jq '.total'
# Expected: 296

# Verify uniqueness in DB
docker compose exec mongo mongosh portfolioradar --quiet --eval \
  'printjson({docs: db.companies.countDocuments(), uniqueIds: db.companies.distinct("companyId").length, uniqueNames: db.companies.distinct("name").length})'
# Expected: {docs: 296, uniqueIds: 296, uniqueNames: 296}

# Verify idempotency (rerun)
docker compose exec app npm run ingest:prod
# Expected: Created: 0, Updated: 0
```

---

## âœ… PHASE 5 â€” REST API (Query & Show Data) (COMPLETE)

**Goal**: Provide endpoints to query and display stored data.
**Status**: âœ… **COMPLETE** â€” REST endpoints, Swagger UI, DTOs with validation, and secure query handling all working.

### What Was Done

1. **Installed Phase 5 dependencies**: `@nestjs/swagger`, `swagger-ui-express`, `class-validator`, `class-transformer`
2. **Created DTOs** (`src/companies/dto/`):
   - `query-companies.dto.ts` â€” Query params with validation (assetClass, industry, region, q, page, limit)
   - `company-response.dto.ts` â€” Response DTOs with Swagger decorators
   - `stats-response.dto.ts` â€” Stats response DTO
3. **Created Companies Service** (`src/companies/companies.service.ts`):
   - Wraps repository methods with DTO transformation
4. **Created Controllers** (`src/companies/companies.controller.ts`):
   - `GET /companies` â€” List with filters + pagination
   - `GET /companies/:id` â€” Single company lookup with 404 handling
   - `GET /stats` â€” Aggregated statistics
5. **Updated main.ts**:
   - Added Swagger configuration at `/api/docs`
   - Added global ValidationPipe with `whitelist`, `forbidNonWhitelisted`, `transform`
6. **Security**: Regex escaping for `q` search parameter to prevent injection/ReDoS

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `src/companies/dto/query-companies.dto.ts` | Created | Query params DTO with validation |
| `src/companies/dto/company-response.dto.ts` | Created | Response DTOs with Swagger decorators |
| `src/companies/dto/stats-response.dto.ts` | Created | Stats response DTO |
| `src/companies/dto/index.ts` | Created | Barrel export |
| `src/companies/companies.service.ts` | Created | Service layer |
| `src/companies/companies.controller.ts` | Created | REST endpoints |
| `src/companies/companies.module.ts` | Modified | Added service + controllers |
| `src/companies/companies.repository.ts` | Modified | Added regex escaping for search |
| `src/main.ts` | Modified | Added Swagger + ValidationPipe |
| `package.json` | Modified | Added swagger + validation dependencies |

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Build passes | `npm run build` | âœ… No errors |
| List companies | `curl localhost:3000/companies?limit=2` | âœ… Returns `{ items, page, limit, total, totalPages }` |
| Filter works | `curl localhost:3000/companies?assetClass=Infrastructure` | âœ… Returns 67 Infrastructure companies |
| Stats endpoint | `curl localhost:3000/stats` | âœ… Returns totalCompanies, byAssetClass, byIndustry, byRegion |
| Swagger UI | Open `http://localhost:3000/api/docs` | âœ… Interactive docs load |
| Validation rejects unknown | `curl localhost:3000/companies?unknownParam=x` | âœ… 400: property should not exist |
| Validation rejects limit > 100 | `curl localhost:3000/companies?limit=200` | âœ… 400: limit must not be greater than 100 |
| Regex safety | `curl localhost:3000/companies?q=.*` | âœ… Returns 0 (escaped, not 296) |
### 5.1 Install Swagger

```bash
npm install @nestjs/swagger swagger-ui-express
```

- [x] Configure in `main.ts`
- [x] Swagger UI at `/api/docs`

### 5.2 Companies Controller

Create `src/companies/companies.controller.ts`:

#### Endpoints

| Method | Path | Description |
|--------|------|-------------|
| GET | `/companies` | List with filters + pagination |
| GET | `/companies/:id` | Get single company |
| GET | `/stats` | Aggregated statistics |

#### Query Parameters for GET /companies

```typescript
@Query() query: {
  assetClass?: string
  industry?: string
  region?: string
  q?: string          // search by name
  page?: number       // default: 1
  limit?: number      // default: 20, max: 100
}
```

### 5.3 DTOs with Validation

```bash
npm install class-validator class-transformer
```

Create `src/companies/dto/`:
- [x] `query-companies.dto.ts`
- [x] `company-response.dto.ts`
- [x] `stats-response.dto.ts`

Enable validation in `main.ts`:
```typescript
app.useGlobalPipes(new ValidationPipe({
  whitelist: true,
  forbidNonWhitelisted: true,
  transform: true,
}));
```

#### ðŸ”’ Security: Allowlisted Filters Only

> **Critical Rule**: Never accept raw MongoDB filter objects from users.

```typescript
// âŒ NEVER do this
@Query('filter') filter: any  // User could inject { $where: "..." }

// âœ… ALWAYS do this
@Query() query: QueryCompaniesDto  // Only known params, validated
```

Build the DB query yourself from validated DTO fields:
```typescript
const mongoFilter = {};
if (dto.assetClass) mongoFilter.assetClasses = dto.assetClass;  // matches any element in array
if (dto.industry) mongoFilter.industry = dto.industry;
if (dto.region) mongoFilter.region = dto.region;  // region is a single string
```

### 5.4 Stats Endpoint

`GET /stats` should return:
```json
{
  "totalCompanies": 296,
  "byAssetClass": { "Private Equity": 148, "Infrastructure": 67, "Tech Growth": 55, ... },
  "byIndustry": { "Financials": 17, "Consumer Discretionary": 30, ... },
  "byRegion": { "Americas": 123, "Asia Pacific": 93, "Europe, The Middle East And Africa": 79, "Japan": 1 }
}
```

### 5.5 Commit

```bash
git add .
git commit -m "feat: add REST API with Swagger, filters, pagination, stats"
```

### Deliverables
- [x] Swagger UI accessible at `/api/docs`
- [x] Can filter companies by asset class, industry, region
- [x] Stats endpoint returns distribution counts

---

## âœ… PHASE 6 â€” Normalization & Derived Fields (Advanced) (COMPLETE)

**Goal**: Improve data quality with computed fields â€” no extra scraping needed.

**Status**: âœ… **COMPLETE** â€” All normalization was implemented in Phase 4 via `company.mapper.ts`. Verified all derived fields are correctly populated during ingestion.

> **Note**: Phase 4 already implemented all normalization requirements. This phase verified correctness.

### What Was Verified

All normalization happens in `src/ingestion/mappers/company.mapper.ts` during ingestion:

1. **`assetClasses[]`** via `splitAssetClasses()`: Splits comma-separated values, trims, filters empties
2. **`descriptionText`** via `stripHtml()`: Removes HTML tags + entities, collapses whitespace
3. **`website`** via `normalizeUrl()`: Adds `https://` if missing, handles empty values
4. **`logoUrl`** via `buildLogoUrl()`: Prefixes `https://www.kkr.com` to relative path
5. **`nameSort`**: Computed as `raw.name.toLowerCase()`
6. **`relatedLinks`**: Optional bonus â€” safely maps `relatedLinkOne`/`relatedLinkTwo` treating values as opaque strings

### Verification Results

| Check | Sample Data | Result |
|-------|-------------|--------|
| `assetClasses[]` split | `"Global Impact, Private Equity"` â†’ `['Global Impact', 'Private Equity']` | âœ… Array with 2 trimmed values |
| `descriptionText` stripped | `"<p>Digital insurance brokerage platform</p>\n"` â†’ `"Digital insurance brokerage platform"` | âœ… No HTML tags |
| `website` normalized | `"www.example.com"` â†’ `"https://www.example.com"` | âœ… Fully qualified |
| `logoUrl` absolute | `/content/dam/kkr/.../logo.png` â†’ `https://www.kkr.com/content/dam/kkr/.../logo.png` | âœ… Absolute URL |
| `nameSort` lowercase | `"+Simple"` â†’ `"+simple"` | âœ… Lowercase |
| Data quality | `npm run verify:data` | âœ… PASS (296 companies, 0 missing fields) |

### 6.1 Key Finding: No Detail Fetch Required

From Phase 0 recon:
- âœ… **All fields are available in the list API response** (description, website, hq, yoi, logo)
- âœ… Opening a company modal in the UI triggers **no additional XHR** â€” it uses cached list data
- âš ï¸ `relatedLinkOne`/`relatedLinkTwo` exist on some companies but are optional bonus content

### 6.2 Normalization Tasks

These should be done in the Response Mapper (Phase 4.2) during ingestion:

- [x] **Asset Classes**: Split `assetClassRaw` by comma into `assetClasses[]`
  ```typescript
  assetClasses: raw.assetClass.split(',').map(s => s.trim())
  // "Global Impact, Private Equity" â†’ ["Global Impact", "Private Equity"]
  ```

- [x] **Description**: Strip HTML for text version
  ```typescript
  descriptionText: raw.description?.replace(/<[^>]*>/g, '').trim()
  // "<p>Digital insurance brokerage</p>\n" â†’ "Digital insurance brokerage"
  ```

- [x] **Website**: Normalize URL scheme
  ```typescript
  website: raw.url ? (raw.url.startsWith('http') ? raw.url : `https://${raw.url}`) : undefined
  // "www.example.com" â†’ "https://www.example.com"
  ```

- [x] **Logo**: Construct full URL
  ```typescript
  logoUrl: raw.logo ? `https://www.kkr.com${raw.logo}` : undefined
  ```

- [x] **Sort Name**: Compute for indexing
  ```typescript
  nameSort: raw.name.toLowerCase()
  ```

- [x] **Region Edge Case**: Kept as-is (Americas, Asia Pacific, Europe/Middle East/Africa, Japan) â€” no silent canonicalization

### 6.3 Related Links (Optional Bonus)

If `relatedLinkOne` or `relatedLinkTwo` are present:

```typescript
relatedLinks: {
  linkOne: raw.relatedLinkOne ? {
    url: raw.relatedLinkOne,  // Usually relative, prefix with base URL
    title: raw.relatedLinkOneTitle || 'Related'
  } : undefined,
  linkTwo: raw.relatedLinkTwo ? {
    urlOrId: raw.relatedLinkTwo,  // Can be URL OR Brightcove video ID!
    title: raw.relatedLinkTwoTitle || 'Related'
  } : undefined
}
```

> âš ï¸ `relatedLinkTwo` can be a numeric video ID (e.g., Brightcove), not always a URL. Treat as string.

### 6.4 Commit

```bash
git add .
git commit -m "feat: add data normalization and computed fields"
```

### Deliverables
- [x] `assetClasses[]` array correctly split from raw value
- [x] `descriptionText` is HTML-stripped
- [x] `website` and `logoUrl` are properly normalized
- [x] `nameSort` enables fast alphabetical sorting
- [x] All normalization happens during ingestion (no separate enrichment step)

---

## âœ… PHASE 7 â€” Production Polish (COMPLETE)

**Goal**: Maximum score on ease of execution, presentation, code quality.

### 7.1 Docker Setup âœ…

Create `Dockerfile` (multi-stage build for reliable `docker compose up --build`):

```dockerfile
# ============ Builder Stage ============
FROM node:20-alpine AS builder
WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci

# Copy source and build
COPY . .
RUN npm run build

# ============ Production Stage ============
FROM node:20-alpine AS production
WORKDIR /app

# Install production dependencies only
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# Copy built app from builder
COPY --from=builder /app/dist ./dist

# Run as non-root user
RUN addgroup -g 1001 -S nodejs && adduser -S nestjs -u 1001
USER nestjs

EXPOSE 3000
CMD ["node", "dist/main"]
```

Create `docker-compose.yml`:
```yaml
services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - MONGO_URI=mongodb://mongo:27017/portfolioradar
    depends_on:
      - mongo
  mongo:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

volumes:
  mongo_data:
```

- [ ] Test: `docker compose up --build`

### 7.2 Testing âœ…

```bash
npm install -D jest @nestjs/testing @types/jest ts-jest
```

Priority tests:
- [x] **Unit**: Company mapper (transform raw â†’ DTO) â€” 29 tests in `company.mapper.spec.ts`
- [x] **Unit**: Pagination logic â€” included in mapper tests
- [ ] **Integration** (optional): Repository upsert behavior

### 7.3 CI Pipeline âœ…

Create `.github/workflows/ci.yml`:
```yaml
name: CI
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
      - run: npm run test
      - run: npm run build
```

### 7.4 Documentation âœ…

Update `README.md` with:

- [x] **Overview**: What this project does
- [x] **Prerequisites**: Node 20, Docker (optional), MongoDB

- [x] **Quick Start (Local)**:
  ```bash
  # Clone & install
  git clone ...
  cd portfolioradar
  npm install
  
  # Configure
  cp .env.example .env
  # Edit .env with your MONGO_URI
  
  # Start MongoDB (if not running)
  docker run -d -p 27017:27017 --name mongo mongo:7
  
  # Ingest data
  npm run ingest
  
  # Verify data quality
  npm run verify:data
  
  # Start API
  npm run start:dev
  
  # Open Swagger
  open http://localhost:3000/api/docs
  ```

- [x] **Quick Start (Docker Compose)** â€” one command:
  ```bash
  # Clone & configure
  git clone ...
  cd portfolioradar
  cp .env.example .env
  
  # Build and run everything
  docker compose up --build
  
  # In another terminal: ingest data
  docker compose exec app npm run ingest
  
  # Open Swagger
  open http://localhost:3000/api/docs
  ```

- [x] **API Examples**: curl commands
- [x] **Design Decisions**: Why API vs scraping, schema choices, idempotency
- [x] **Project Structure**: Brief folder overview

> **Note**: Keep time estimates in your personal notes, but remove from final README (reviewers don't need them).

### 7.5 Final Commits

```bash
git add .
git commit -m "chore: add Docker, CI pipeline, tests"
git commit -m "docs: complete README with setup and usage"
```

### Deliverables âœ…
- [x] `docker compose up` works end-to-end
- [x] Tests pass (30 total: 1 app + 29 mapper)
- [x] README is clear and complete

### Phase 7 Verification Summary

**Date Completed**: $(date)

**Artifacts Created**:
- `Dockerfile` â€” Multi-stage build, Node 20 Alpine, non-root user
- `docker-compose.yml` â€” App + MongoDB services with healthcheck
- `.dockerignore` â€” Build exclusions
- `.github/workflows/ci.yml` â€” Lint, test, build, docker pipeline
- `src/ingestion/mappers/company.mapper.spec.ts` â€” 29 unit tests

**Test Results**:
```
âœ“ 30 tests passing
âœ“ Lint clean
âœ“ Build successful
```

---

## âšª PHASE 8 â€” Bonus Features (Optional)

> âš ï¸ **Only if all above phases are 100% complete and polished**
> 
> These items map directly to the **Bonus Points** section of the Berry Code Challenge evaluation criteria.

---

### 8.1 UX â€” Effectiveness of Interaction âœ…

> **Evaluation**: "Effectiveness of interaction (REST API, CLI, UI, DB Console)"

**Status**: âœ… **COMPLETE** â€” HATEOAS links, consistent error format, CLI docs, and mongosh one-liners all implemented.

**Already done** (Phases 5 & 7):
- [x] REST API with filters, pagination, and search (`GET /companies`, `GET /companies/:id`, `GET /stats`)
- [x] Swagger UI at `/api/docs` for interactive API exploration
- [x] Docker Compose for one-command setup

**Completed enhancements**:
- [x] **CLI commands documented**: `npm run ingest`, `npm run verify:data` with expected output in README
- [x] **API response improvements**: HATEOAS-style pagination links (`_links.self`, `_links.prev`, `_links.next`, `_links.first`, `_links.last`)
- [x] **Consistent error format**: Global `HttpExceptionFilter` with standardized error responses (statusCode, error, message, path, timestamp)
- [x] **DB Console queries**: Comprehensive `mongosh` one-liners documented in README for reviewers

### Verification Results

| Check | Command | Result |
|-------|---------|--------|
| Lint passes | `npm run lint` | âœ… No errors |
| Build passes | `npm run build` | âœ… No errors |
| Tests pass | `npm run test` | âœ… 37 tests passing |
| HATEOAS links | `curl localhost:3000/companies?limit=2 \| jq '._links'` | âœ… `{self, prev, next, last}` |
| Error format | `curl localhost:3000/companies/nonexistent` | âœ… `{statusCode, error, message, path, timestamp}` |
| Docker works | `docker compose up --build` | âœ… App + Mongo start, API responds |

### Files Created/Modified

| File | Status | Description |
|------|--------|-------------|
| `src/common/filters/http-exception.filter.ts` | Created | Global exception filter for consistent errors |
| `src/common/filters/index.ts` | Created | Barrel export |
| `src/main.ts` | Modified | Register global HttpExceptionFilter |
| `src/companies/dto/company-response.dto.ts` | Modified | Added `PaginationLinksDto` and `_links` field |
| `src/companies/companies.service.ts` | Modified | Added `buildPaginationLinks()` method |
| `README.md` | Modified | CLI usage guide + mongosh one-liners

---

### 8.2 Linter â€” Code Quality Tooling

> **Evaluation**: "Use of linter to improve code quality"

**Already done** (Phase 1):
- [x] ESLint configured via `eslint.config.mjs`
- [x] Prettier for code formatting
- [x] `npm run lint` and `npm run format` scripts
- [x] CI pipeline runs lint check on every push

**Remaining enhancements** (Completed):
- [x] Add stricter ESLint rules (`no-floating-promises`, `no-unused-vars`, `no-return-await` as error)
- [x] Add `lint-staged` + `husky` for pre-commit hooks (auto-lint on commit)

---

### 8.3 Container â€” Dockerization & Registry

> **Evaluation**: "App is containerized (Docker), image is pushed to container registry"

**Already done** (Phase 7):
- [x] Multi-stage `Dockerfile` (Node 20 Alpine, non-root user)
- [x] `docker-compose.yml` with App + MongoDB services
- [x] `.dockerignore` for build exclusions
- [x] `docker compose up --build` works end-to-end

**Remaining enhancements**:
- [ ] **Push image to container registry** (Docker Hub or GitHub Container Registry):
  ```bash
  # Tag and push to Docker Hub
  docker build -t <username>/portfolioradar:latest .
  docker push <username>/portfolioradar:latest
  
  # Or GitHub Container Registry
  docker build -t ghcr.io/<username>/portfolioradar:latest .
  docker push ghcr.io/<username>/portfolioradar:latest
  ```
- [ ] **Add Docker image build to CI pipeline** (`.github/workflows/ci.yml`):
  ```yaml
  - name: Build and push Docker image
    uses: docker/build-push-action@v5
    with:
      push: true
      tags: ghcr.io/${{ github.repository }}:latest
  ```
- [ ] Add health check in `docker-compose.yml` for app service (using `/health` endpoint)

---

### 8.4 Configuration Management â€” Env Vars & Secrets

> **Evaluation**: "Use of environment variables vs hardcoded variables; Secrets management"

**Already done** (Phase 2):
- [x] `@nestjs/config` with Zod validation (`src/config/env.validation.ts`)
- [x] `.env.example` with documented variables
- [x] `.env` git-ignored (never committed)
- [x] App fails fast with clear error if required env vars are missing

**Remaining enhancements**:
- [ ] **Secrets management**: Document how to handle secrets in production:
  - Use cloud provider secret managers (AWS Secrets Manager, GCP Secret Manager, etc.)
  - Use Docker secrets or Kubernetes secrets for containerized deployments
  - Never log sensitive values (mask `MONGO_URI` in logs)
- [ ] **Environment-specific configs**: Support `NODE_ENV` to toggle behavior (e.g., `development` vs `production` logging level)
- [ ] **Add optional env vars** for bonus features:
  ```bash
  # .env.example additions
  NODE_ENV=development          # development | production
  LOG_LEVEL=info                # debug | info | warn | error
  RATE_LIMIT_TTL=60             # Rate limit window in seconds
  RATE_LIMIT_MAX=100            # Max requests per window
  ```

---

### 8.5 Deployment â€” Cloud Hosting

> **Evaluation**: "App deployed online and works remotely"

- [ ] **Deploy to a cloud platform** (pick one):

  | Platform | Pros | Notes |
  |----------|------|-------|
  | **Railway** | Easy, free tier, supports Docker | Recommended for speed |
  | **Render** | Free tier, auto-deploy from Git | Good alternative |
  | **Fly.io** | Edge deployment, Docker-native | More config needed |
  | **AWS ECS / GCP Cloud Run** | Production-grade | Overkill for demo |

- [ ] **Use managed MongoDB** (e.g., MongoDB Atlas free tier) for the deployed instance
- [ ] **Document the live URL** in README:
  ```markdown
  ## ðŸŒ Live Demo
  - API: https://portfolioradar.example.com/companies
  - Swagger: https://portfolioradar.example.com/api/docs
  ```
- [ ] Ensure ingestion can run against the deployed instance

---

### 8.6 Tests â€” Automated Testing & Coverage

> **Evaluation**: "Automated tests, test effectiveness and coverage"

**Already done** (Phase 7):
- [x] 29 unit tests for `company.mapper.ts` (`company.mapper.spec.ts`)
- [x] 1 app controller test (`app.controller.spec.ts`)
- [x] CI runs `npm run test` on every push

**Remaining enhancements**:
- [ ] **Integration tests**: Test repository upsert behavior with in-memory MongoDB
  ```bash
  npm install -D mongodb-memory-server
  ```
- [ ] **E2E tests**: Test REST endpoints end-to-end (`test/app.e2e-spec.ts`)
  ```bash
  npm run test:e2e
  ```
- [ ] **Test coverage reporting**:
  ```bash
  npm run test -- --coverage
  ```
  - Add coverage thresholds to `jest` config (e.g., 80% lines)
  - Add coverage badge to README
- [ ] **Additional unit tests**:
  - KKR client (mock HTTP responses)
  - Companies service (mock repository)
  - DTOs validation (edge cases)

---

### 8.7 CI/CD â€” Continuous Integration & Deployment

> **Evaluation**: "Use of CI/CD pipelines"

**Already done** (Phase 7):
- [x] GitHub Actions CI pipeline (`.github/workflows/ci.yml`): lint â†’ test â†’ build â†’ docker

**Remaining enhancements**:
- [ ] **Continuous Deployment (CD)**: Auto-deploy on merge to `main`
  ```yaml
  # .github/workflows/cd.yml
  name: CD
  on:
    push:
      branches: [main]
  jobs:
    deploy:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v4
        - name: Deploy to Railway/Render/Fly.io
          # Platform-specific deploy step
  ```
- [ ] **Test coverage in CI**: Fail pipeline if coverage drops below threshold
- [ ] **Docker image publish in CI**: Build and push image to registry on tagged releases
- [ ] **Status badges in README**:
  ```markdown
  ![CI](https://github.com/<user>/portfolioradar/actions/workflows/ci.yml/badge.svg)
  ```

---

### 8.8 Security Hardening

```bash
npm install helmet @nestjs/throttler
```

- [ ] **Helmet** â€” Set secure HTTP headers:
  ```typescript
  import helmet from 'helmet';
  app.use(helmet());
  ```
- [ ] **Rate limiting** â€” Prevent abuse with `@nestjs/throttler`:
  ```typescript
  ThrottlerModule.forRoot([{ ttl: 60000, limit: 100 }])
  ```
- [ ] **CORS configuration** â€” Restrict origins in production:
  ```typescript
  app.enableCors({ origin: process.env.ALLOWED_ORIGINS?.split(',') || '*' });
  ```
- [ ] **Input size limits** â€” Prevent oversized payloads:
  ```typescript
  app.use(json({ limit: '1mb' }));
  ```

---

### 8.9 AI Integration

> **Evaluation**: "Use of AI is encouraged. Poor understanding of AI-generated code/logic will negatively affect evaluation."

- [ ] Document AI usage in README or a dedicated `docs/AI_USAGE.md`:
  - Which tools were used (e.g., GitHub Copilot, ChatGPT)
  - What was AI-assisted vs manually written
  - Key decisions and trade-offs understood
- [ ] **Critical**: Be prepared to explain every piece of code during presentation â€” AI-generated code you don't understand will hurt your score

---

### Phase 8 Checklist Summary

| Bonus Category | Status | Priority |
|----------------|--------|----------|
| UX (REST API + Swagger + HATEOAS) | âœ… Done (Phase 8.1) | â€” |
| Linter (ESLint + Prettier) | âœ… Done (Phase 1) | â€” |
| Container (Docker + Compose) | âœ… Done (Phase 7) | â€” |
| Config Management (env vars) | âœ… Done (Phase 2) | â€” |
| Push image to registry | â¬œ Not started | ðŸŸ¡ Medium |
| Cloud deployment | â¬œ Not started | ðŸŸ¡ Medium |
| Extended test coverage | â¬œ Not started | ðŸŸ¡ Medium |
| CD pipeline | â¬œ Not started | ðŸŸ¢ Low |
| Security hardening | â¬œ Not started | ðŸŸ¢ Low |
| Pre-commit hooks | â¬œ Not started | ðŸŸ¢ Low |
| AI usage documentation | â¬œ Not started | ðŸŸ¢ Low |

---

## ðŸ“Š Work Order Summary

| Order | Phase | Priority | Notes |
|-------|-------|----------|-------|
| 1 | Phase 0: Source Recon | âœ… Complete | See `docs/source-analysis.md` |
| 2 | Phase 1: Repo Setup | ðŸŸ¡ High | NestJS scaffold + lint |
| 3 | Phase 2: Config + DB | ðŸŸ¡ High | Fail-fast config, MongoDB connection |
| 4 | Phase 3: Data Model | ðŸŸ¡ High | Schema + deterministic hash key |
| 5 | Phase 4: Ingestion | ðŸŸ¢ Core | The main deliverable |
| 6 | Phase 5: REST API | ðŸŸ¢ Core | Query + Swagger UI |
| 7 | Phase 6: Normalization | ðŸŸ¢ Advanced | Computed fields (no extra scraping) |
| 8 | Phase 7: Polish | ðŸ”µ Important | Docker, tests, CI, docs |
| 9 | Phase 8: Bonus | âšª Optional | Only if everything else is 100% |

**Delivery target**: ~1 week (adjust based on experience)

---

## ðŸ’¡ Tips for Success

1. **Commit often** with meaningful messages
2. **Test incrementally** â€” verify each phase works before moving on
3. **Phase 0 is done** â€” reference `docs/source-analysis.md` for all API details
4. **Prioritize working software** over bonus features
5. **Document as you go** â€” don't leave README for last
6. **Use `npx`** over global installs for reproducibility
7. **Verify with commands** â€” `npm run verify:data`, `npm run lint`, etc.
8. **Two ways to run** â€” document both local and Docker approaches
9. **Security matters** â€” never accept raw filters, always allowlist
10. **Never store `sortingName`** â€” it changes based on sort parameter; use your own `nameSort`

Good luck! ðŸš€
